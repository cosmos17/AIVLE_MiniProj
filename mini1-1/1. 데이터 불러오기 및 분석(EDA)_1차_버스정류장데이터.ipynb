{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "boxed-jamaica",
   "metadata": {},
   "source": [
    "# 안녕하세요^^ \n",
    "## AIVLE 미니프로젝트 '서울시 생활정보 기반 대중교통 수요 분석 ' 과정에 오신 여러분을 환영합니다.\n",
    "* 본 과정에서는 실제 사례와 데이터를 기반으로 문제를 해결하는 전체 과정을 자기 주도형 실습으로 진행해볼 예정입니다.\n",
    "* 앞선 교육과정을 정리하는 마음과 지금까지 배운 내용을 바탕으로 문제 해결을 해볼게요!\n",
    "* 미니 프로젝트를 통한 문제 해결 과정 'A에서 Z까지', 지금부터 시작합니다!\n",
    "\n",
    "## 개인과제\n",
    "* 데이터 구조, 분포 확인, 전처리 : 1.1_버스정류장데이터 / 1.2 유동인구데이터 / 1.3_주민등록데이터 / 1.4_업종등록데이터\n",
    "* 데이터간 관계 가설 수립 및 검증 : 1.5_데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef575059",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc4fa5",
   "metadata": {},
   "source": [
    "# 데이터 분석부터 먼저 시작해보겠습니다.\n",
    "## \"버스 정류장 데이터\" 를 확인해 보도록 하겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ced42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리부터 설치합니다.\n",
    "#%pip install pandas seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-farmer",
   "metadata": {},
   "source": [
    "## 데이터 안내\n",
    "\n",
    "[기본 데이터]\n",
    "* 1.1 BUS_STATION_BOARDING_MONTH_202204.csv\n",
    "\n",
    "* 서울시 버스노선별 정류장별 승하차 인원 정보\n",
    "* https://data.seoul.go.kr/dataList/OA-12912/S/1/datasetView.do\n",
    "\n",
    "\n",
    "[추가 데이터]\n",
    "* 1.1 bus_station.csv\n",
    "\n",
    "* 서울시 버스정류장 위치정보\n",
    "* https://data.seoul.go.kr/dataList/OA-15067/S/1/datasetView.do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-broad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-gentleman",
   "metadata": {},
   "source": [
    "# 1.데이터 불러오기\n",
    "## 모든 미니 프로젝트의 시작은 '데이터 불러오기' 부터라고 할 수 있습니다.\n",
    "+ KeyPoint : 불러오고자 하는 데이터에 따라 자유롭게 변수로 지정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-administration",
   "metadata": {},
   "source": [
    "###  데이터 프레임을 불러오고 변수로 저장(여기서는 CSV 기준으로 진행)\n",
    "* csv : pd.read_csv(\"파일이름. csv\")\n",
    "* txt : pd.read_csv(\"파일이름. csv\", sep=\"구분자\")\n",
    "* xlsx : pd.read_excel('파일이름.xlsx')\n",
    "* pickle : pd.read_pickle(\"파일이름.pkl\") <br>\n",
    " [참고] pickle은 파이썬의 모든 객체를 파일로 저장할 수 있는 방법으로 DataFrame,List,Dict 등 모든 객체 저장 가능(특히 sklearn라이브러리를 통해 모델을 학습시키고, 저장할 때 많이 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-animal",
   "metadata": {},
   "source": [
    "#### [실습문제1] 데이터 로딩\n",
    "* Pandas 라이브러리를 활용해서 '1.1 BUS_STATION_BOARDING_MONTH_202204.csv'파일을 'bus_station' 변수에 저장하세요.\n",
    "    * 데이터 파일 로딩시 참고 사항 \n",
    "        * 구분자(sep)는 ',' 입니다\n",
    "        * cp949 인코더를 사용해 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd83ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "saving-slope",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1.1 BUS_STATION_BOARDING_MONTH_202204.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 아래에 실습코드를 작성하고 결과를 확인합니다.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m bus_station \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1.1 BUS_STATION_BOARDING_MONTH_202204.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp949\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m bus_station\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:610\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    605\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    606\u001b[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    607\u001b[0m )\n\u001b[0;32m    608\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:462\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    459\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    461\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:819\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 819\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:1050\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m     )\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[1;32m-> 1050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:1867\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1864\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[1;32m-> 1867\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:1362\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1359\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHanldes after they are done with their potential raises.\u001b[39;00m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:642\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m         errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1.1 BUS_STATION_BOARDING_MONTH_202204.csv'"
     ]
    }
   ],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "bus_station = pd.read_csv('1.1 BUS_STATION_BOARDING_MONTH_202204.csv', encoding='cp949')\n",
    "bus_station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임의 Shape을 확인합니다.\n",
    "bus_station.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73396b42",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-trout",
   "metadata": {},
   "source": [
    "# 2.기본 정보 확인 및 클렌징\n",
    "\n",
    "+ 데이터 클렌징 : 결측치, 이상치 등을 제거하여 데이터 분석 결과가 왜곡 되는 문제를 방지하기 위한 정제 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-johnson",
   "metadata": {},
   "source": [
    "#### [실습문제2] 기본 정보 확인하기\n",
    "* 'bus_station' 데이터의 정보를 확인해보세요.\n",
    "* 'describe', 'info', 'head' 등 전부 활용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "bus_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77b32f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "bus_station.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "bus_station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "bus_station.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888898f",
   "metadata": {},
   "source": [
    "#### [실습문제3] 위 데이터에서 버스정류장 위치를 구 별로 구분 하고 싶습니다.\n",
    "\n",
    "* 'bus_station' 데이터의 정보를 확인해보세요.\n",
    "\n",
    "* 어떻게 해야 할까요?? (tip! 버스정류장ARS번호의 앞 두자리가 구를 의미합니다.)\n",
    "\n",
    "* '자치구' column을 추가하여 정류장이 위치한 구 이름을 등록해주세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus_station에서 버스정류장ARS번호의 정보를 확인해보세요.\n",
    "bus_station['버스정류장ARS번호']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056437b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버스정류장 ARS 번호의 앞자리 2개로 새로 컬럼 생성합니다\n",
    "bus_station['busARS00'] = bus_station['버스정류장ARS번호'].str[:2]\n",
    "bus_station.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97c502",
   "metadata": {},
   "source": [
    "* 버스정류장 ARS 번호 - 01~25까지 앞 숫자 두개가 위치한 구를 의미\n",
    "    01. 종로구    02. 중구    03. 용산구    04. 성동구    05. 광진구\n",
    "    06. 동대문구    07. 중랑구    08. 성북구    09. 강북구    10. 도봉구\n",
    "    11. 노원구    12. 은평구    13. 서대문구    14. 마포구    15. 양천구\n",
    "    16. 강서구    17. 구로구    18. 금천구    19. 영등포구    20. 동작구\n",
    "    21. 관악구    22. 서초구    23. 강남구    24. 송파구    25. 강동구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43cdae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구 코드를 구 이름으로 변환합니다\n",
    "bus_station['GuCode'] = bus_station['busARS00'].map({\n",
    "    '01':'종로구',    '02':'중구',    '03':'용산구',    '04':'성동구',    '05':'광진구',\n",
    "    '06':'동대문구',    '07':'중랑구',    '08':'성북구',    '09':'강북구',    '10':'도봉구',\n",
    "    '11':'노원구',    '12':'은평구',    '13':'서대문구',    '14':'마포구',    '15':'양천구',\n",
    "    '16':'강서구',    '17':'구로구',    '18':'금천구',    '19':'영등포구',    '20':'동작구',\n",
    "    '21':'관악구',    '22':'서초구',    '23':'강남구',    '24':'송파구',    '25':'강동구'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다. (head, tail 등)\n",
    "display(bus_station.head())\n",
    "display(bus_station.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0606db26",
   "metadata": {},
   "source": [
    "#### [실습문제4] 결측치를 처리 합시다 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (가상기점),(가상종점)때문에 ARS번호가 '~'로 나오는 곳이 있습니다 확인해볼까요?\n",
    "bus_station.loc[bus_station['버스정류장ARS번호'] =='~']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728bd3e-6897-415d-b78f-f018cac03d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_station.loc[bus_station['GuCode'].isnull()] # 가상, 가상기점, 가상종점, 서울외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN 값을 제거 하겠습니다\n",
    "bus_station.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9342f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 bus_station의 정보를 확인해볼까요?\n",
    "bus_station.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae560474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버스정류장ARS번호의 type을 변경해볼까요?\n",
    "bus_station = bus_station.astype({'버스정류장ARS번호':'int'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003322b3",
   "metadata": {},
   "source": [
    "#### [실습문제5] 구별로 버스정류장이 몇 개 있는지 궁금합니다\n",
    "\n",
    "* 구별로 버스 정류장의 개수를 확인해 주세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nunique로 고유값의 갯수만 확인해볼게요\n",
    "bus_station.groupby('GuCode')['버스정류장ARS번호'].nunique()\n",
    "#bus_station['GuCode'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강남구와 서초구에 500 개가 넘는 버스정류장이 있다는데, 확인해봅시다.\n",
    "bus_23 = bus_station.loc[(bus_station['GuCode']=='강남구')]# | (bus_station['GuCode']=='서초구')]\n",
    "bus_23['버스정류장ARS번호'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울의 버스 정류장 데이터만 포함하고 있는 csv 파일 입니다 (서울 공공데이터 포탈)\n",
    "# https://data.seoul.go.kr/dataList/OA-15067/S/1/datasetView.do\n",
    "seoul_bus_st = pd.read_csv('1.1 bus_station.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울의 버스정류장 데이터의 정보를 확인해보세요.\n",
    "seoul_bus_st.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2291dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 자세히 살펴볼까요?\n",
    "seoul_bus_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f35a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아까 전에 네이버 지도로 확인했던 정류장ARS번호를 찾아볼까요?\n",
    "bus_station.loc[(bus_station['버스정류장ARS번호'] == 23783)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 컬럼명을 바꿔볼까요? (to 버스정류장ARS번호)\n",
    "seoul_bus_st.rename(columns={'ARS-ID':'버스정류장ARS번호'}, inplace=True)\n",
    "seoul_bus_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2880e37-857b-4ad3-be40-7fd9c517e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_station.groupby('버스정류장ARS번호', as_index=True)[['GuCode']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8214ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울시 버스정류장 데이터와 bus_station을 합쳐볼까요?\n",
    "seoulbus = pd.merge(bus_station, seoul_bus_st, how='inner', on='버스정류장ARS번호')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합쳐진 데이터를 확인해볼까요?\n",
    "seoulbus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구 별로 버스 정류장의 개수를 확인해 주세요\n",
    "seoulbus.groupby('GuCode', as_index=False)[['버스정류장ARS번호']].nunique() # why count() x?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버스정류장ARS번호 갯수를 확인해볼까요?\n",
    "seoulbus['버스정류장ARS번호'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33564b09",
   "metadata": {},
   "source": [
    "#### [실습문제6] 구 별로 버스 노선이 몇 개나 지나가는지 궁금합니다.\n",
    "\n",
    "* 구별로 버스 노선의 개수를 확인해 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "seoulbus.groupby('GuCode', as_index=False)[['노선번호']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666e46c",
   "metadata": {},
   "source": [
    "#### [실습문제7] 각 구별로 승차 총 승객수, 하차 총 승객수를 알아봅시다\n",
    "\n",
    "* groupby 를 활용해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "seoulbus.groupby('GuCode', as_index=False)[['승차총승객수', '하차총승객수']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcb6d4",
   "metadata": {},
   "source": [
    "#### [실습문제8] 각 구별로 승차 평균 승객수, 하차 평균 승객수를 알아봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f73cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "seoulbus.groupby('GuCode', as_index=False)[['승차총승객수', '하차총승객수']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f329891",
   "metadata": {},
   "source": [
    "#### [실습문제9] 데이터 프레임을 합쳐보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc284dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네 개 파일을 합쳐볼까요\n",
    "\n",
    "seoul_bus_station_ARS = seoulbus.groupby('GuCode', as_index=False)[['버스정류장ARS번호']].nunique()\n",
    "seoul_bus_station_line = seoulbus.groupby('GuCode', as_index=False)[['노선번호']].nunique()\n",
    "seoul_bus_station_sum = seoulbus.groupby('GuCode', as_index=False)[['승차총승객수', '하차총승객수']].sum()\n",
    "seoul_bus_station_mean = seoulbus.groupby('GuCode', as_index=False)[['승차총승객수', '하차총승객수']].mean()\n",
    "\n",
    "temp1 = pd.merge(seoul_bus_station_ARS, seoul_bus_station_line, how='inner', on='GuCode')\n",
    "temp2 = pd.merge(temp1, seoul_bus_station_sum, how='inner', on='GuCode')\n",
    "seoulbus_stations = pd.merge(temp2, seoul_bus_station_mean, how='inner', on='GuCode')\n",
    "\n",
    "seoulbus_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "seoulbus_stations.rename(columns={'GuCode':'구이름',\n",
    "                                 '버스정류장ARS번호':'버스정류장개수',\n",
    "                                  '노선번호':'버스노선개수',\n",
    "                                 '승차총승객수_x':'승차총승객수',\n",
    "                                  '하차총승객수_x':'하차총승객수',\n",
    "                                  '승차총승객수_y':'승차평균승객수',\n",
    "                                  '하차총승객수_y':'하차평균승객수'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "seoulbus_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 데이터프레임을 'df_seoul_bus_station.csv' 파일로 저장하세요.\n",
    "seoulbus_stations.to_csv('df_seoul_bus_station.csv', mode='w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b8bae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-integration",
   "metadata": {},
   "source": [
    "# 3.데이터 분석하기\n",
    "+ KeyPoint : 데이터의 형태를 살펴보고 다양한 분석기법을 통해 모델링에 적합하도록 정제요소를 선별할 수 있다.\n",
    "  * 데이터들의 패턴 탐색\n",
    "  * 변수들간의 관계 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ae01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 시각화 한글폰트 설정\n",
    "# 맑은 고딕\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "sns.set(font=\"Malgun Gothic\",#\"NanumGothicCoding\", \n",
    "        rc={\"axes.unicode_minus\":False}, # 마이너스 부호 깨짐 현상 해결\n",
    "        style='darkgrid')\n",
    "\n",
    "# scipy\n",
    "import scipy.stats as spst  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-complex",
   "metadata": {},
   "source": [
    "#### [실습문제10] 데이터 분포 알아보기\n",
    "* 다양한 변수를 기준으로 그래프를 그려보고 인사이트를 도출해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4c8ca-a42d-4f7a-b74c-71f162ed9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot('구이름', '버스정류장개수', data = seoulbus_stations)\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel('버스정류장개수')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot('구이름', '승차총승객수', data = seoulbus_stations)\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel('승차총승객수')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot('구이름', '승차평균승객수', data = seoulbus_stations)\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel('승차평균승객수')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f007f86-8dbb-451a-8fc6-d8c8f08c5239",
   "metadata": {},
   "source": [
    "* 위 차트를 통해 알게된 사실을 정리해봅시다.\n",
    "    * 1. \n",
    "    * 2. \n",
    "    * 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca567b34",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
